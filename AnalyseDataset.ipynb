{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_train_data(file_path: str) -> dict:\n",
    "    counter = Counter()\n",
    "    total_tokens = 0\n",
    "    total_sentences = 0\n",
    "    total_word_length = 0\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        sentences = sent_tokenize(text)\n",
    "        total_sentences += len(sentences)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            tokens = word_tokenize(sentence)\n",
    "            total_tokens += len(tokens)\n",
    "            total_word_length += sum(len(token) for token in tokens)\n",
    "            counter.update(tokens)\n",
    "\n",
    "    total_types = len(counter)\n",
    "    total_words = sum(counter.values())\n",
    "    average_words_per_sentence = total_words / total_sentences\n",
    "    average_word_length = total_word_length / total_words\n",
    "\n",
    "    words = list(counter.elements())\n",
    "    tagged = pos_tag(words)\n",
    "    pos_counter = Counter(tag for word, tag in tagged)\n",
    "    most_common_pos = pos_counter.most_common(10)\n",
    "\n",
    "    return {\n",
    "        'total_tokens': total_tokens,\n",
    "        'total_types': total_types,\n",
    "        'total_words': total_words,\n",
    "        'average_words_per_sentence': average_words_per_sentence,\n",
    "        'average_word_length': average_word_length,\n",
    "        'most_common_pos': most_common_pos,\n",
    "        'word_frequencies': counter,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH: str = \"babylm_data\"\n",
    "RESULTS_PATH: str = \"results\"\n",
    "os.makedirs(RESULTS_PATH) if not os.path.exists(RESULTS_PATH) else None\n",
    "\n",
    "for experiment in [\"babylm_10M\", \"babylm_100M\"]:\n",
    "\n",
    "    file_paths: list[str] = [\n",
    "        f\"{DATASET_PATH}/{experiment}/aochildes.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/bnc_spoken.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/cbt.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/children_stories.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/gutenberg.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/open_subtitles.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/qed.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/simple_wikipedia.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/switchboard.train\",\n",
    "        f\"{DATASET_PATH}/{experiment}/wikipedia.train\",\n",
    "    ]\n",
    "\n",
    "    experiment_results_target_path: str = f\"{RESULTS_PATH}/{experiment}.json\"\n",
    "    results: list[dict] = []\n",
    "    for file_path in file_paths:\n",
    "        print(f\"Processing [{file_path}] ...\")\n",
    "        result: dict = analyse_train_data(file_path)\n",
    "        results.append(result)\n",
    "        \n",
    "        # store last computed results\n",
    "        with open(experiment_results_target_path, \"w\") as file:\n",
    "            print(f\"Saving last results to [{experiment_results_target_path}]\")\n",
    "            file.write(json.dumps(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
